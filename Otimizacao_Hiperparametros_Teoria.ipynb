{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Otimizacao_Hiperparametros_Teoria.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPb8//D27E7Q4Hh9E1ng9c6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThiagueraBarao/Otimizacao_de_Hiperparametros/blob/master/Otimizacao_Hiperparametros_Teoria.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2AvOwegOceM",
        "colab_type": "text"
      },
      "source": [
        "# **Otimização de Hiperparâmetros**\n",
        "\n",
        "### Autor: Thiago do Carmo Nunes\n",
        "### Acesse em: [thiagocarmonunes.com.br](https://www.thiagocarmonunes.com.br/)\n",
        "#### Publicado em :  19-Jul-2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMeB25rhshPL",
        "colab_type": "text"
      },
      "source": [
        "# **Uma breve discussão teórica sobre o tema**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFt1kDGevKmb",
        "colab_type": "text"
      },
      "source": [
        "## **Parâmetros e Hiperparâmetros:**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAkI_W4jvKp8",
        "colab_type": "text"
      },
      "source": [
        "### **Parâmetros:**\n",
        "\n",
        "Modelos probabilísticos são caracterizados por quantidades desconhecidas, denominadas parâmetros. Estes são ajustados a partir de uma técnica de otimização para que na amostra de dados de treinamento seja possível encontrar um padrão da melhor maneira possível. De maneira simples , parâmetros são estimados pelo algoritmo e o usuário possui pouco/nada controle sobre eles.\n",
        " \n",
        "\n",
        "> Em uma regressão linear simples os parâmetros do modelo são os betas (**ẞ**).\n",
        "![texto alternativo](https://image.slidesharecdn.com/10regressaopartei-160804214203/95/regresso-linear-i-21-638.jpg?cb=1500399128)\n",
        "\n",
        "**BAM!!!** : Em estatística parâmetros são definidos como características populacionais. Portanto a rigor, quando queremos falar de características amostrais recorremos ao termo estimadores. Isso faz pouca diferença neste contexto, mas é importante ressaltar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sP7Z2GVmvKsb",
        "colab_type": "text"
      },
      "source": [
        "### **Hiperparâmetros** :\n",
        "\n",
        "\n",
        "Hiperparâmetros são conjuntos de informações que são utilizadas para controlar o aprendizado de um algoritmo. A suas definições impactam os parâmetros dos modelos, visto que a forma de aprender muda a partir de novos hiperparâmetros. Este conjunto de valores afeta de forma considerável a performance, estabilidade e a interpretação de um modelo.\n",
        "\n",
        "Cada algoritmo demanda uma escolha específica de hiperparâmetros que podem e devem ser ajustadas de acordo com o problema de negócio.\n",
        "\n",
        "Os hiperparâmetros alteram o aprendizado de um modelo e a partir disto o algoritmo de treinamento aprende os parâmetros para gerar os outputs.\n",
        "\n",
        "> Em uma árvore de decisão um dos principais hiperparâmetros é a profundidade da árvore e número de indivíduos presentes em cada folha.\n",
        "![Arvore profundidade 2](https://miro.medium.com/max/1990/1*tMU0XhEbj5aKgGt9RX-UQQ.png)\n",
        "\n",
        "\n",
        "\n",
        "**ALERTA + BAM!!!** : Hiperparâmetros não devem ser escolhidos em um arranjo de dados Treino+Teste. Devemos tomar muito cuidado nisso.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IslPYfndvKuv",
        "colab_type": "text"
      },
      "source": [
        "## **Divisão de DataSet:**\n",
        "\n",
        "---\n",
        "\n",
        "Quando o objetivo é definir os hiperparâmetros utilizados o arranjo de dados deve ser pensado com a  seguinte quebra:\n",
        "\n",
        "1.   Treino: Conjunto de dados para treinar o algoritmo variando seus hiperparametros;\n",
        "2.   Validação: Conjunto onde serão aplicadas métricas de performance para validar os hiperparâmetros;\n",
        "3.   Teste: Conjunto separado para validar efetivamente a performance do seu modelo.\n",
        "\n",
        "\n",
        "![Train/Valid/Test](https://cdn-images-1.medium.com/max/1000/1*ZiYvylk60EY2XG7ck1lqJA.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKwctmh3vK0I",
        "colab_type": "text"
      },
      "source": [
        "## **Escolha dos Hiperparâmetros:**\n",
        "\n",
        "---\n",
        "\n",
        "Para o processo de escolha serão abordadas 4 técnicas :\n",
        "\n",
        "\n",
        "1.   Conhecimento de Negócio;\n",
        "2.   Grid Search;\n",
        "2.   Random Search;\n",
        "2.   Otimização Bayesiana.\n",
        "\n",
        "### **Conhecimento de Negócio:**\n",
        "\n",
        "A escolha de hiperparâmetros por conhecimento de negócio é de longe a mais complexa. Ela exige que você consiga abstrair o seu modelo e encaixar premissas e comportamentos esperados a partir de estudos prévios ou conhecimento de negócio para uma escolha mais adequada. Nesta etapa também é muito frequente se embasar em artigos e publicações científicas que apoiam a escolha de conjuntos de hiperparâmetros para maior sucesso na resolução do problema.\n",
        "\n",
        "**Obs!!!** : Na minha opinião é a melhor forma de se iniciar um algoritmo de otimização. Porém é mais complexa e demanda muita experiência e leitura do cientista.\n",
        "\n",
        "\n",
        "### **Grid Search:**\n",
        "\n",
        "Grid Search combina uma seleção de hiperparâmetros estabelecidos pelo cientista e percorre por todos eles para avaliar a performance do modelo. A sua vantagem é que é uma técnica simples e que vai percorrer todas as combinações programadas. A maior desvantagem é que ele percorre uma região específica do espaço de parâmetros e não consegue entender qual movimentação ou qual região do espaço é importante para otimizar o modelo.\n",
        "\n",
        "![Grid Search](https://cdn-images-1.medium.com/freeze/max/1000/1*6mLLIGYLny9B6GAnVZcltw.png?q=20)\n",
        "\n",
        "\n",
        "### **Random Search:**\n",
        "\n",
        "No Random Search os hiperparâmetros são escolhidos de forma aleatória dentro de um range de valores que que este pode assumir. A vantagem deste método é que existe uma chance maior de encontrarmos regiões do espaço de minimização de custo com hiperparâmetros mais adequados, visto que a escolha para cada iteração é aleatória. A desvantagem deste método é que a combinação de hiperparâmetros está fora do controle do cientista.\n",
        "\n",
        "![Random Search](https://cdn-images-1.medium.com/freeze/max/1000/1*ijBbgo-2nyMdHLc40_zgQQ.png?q=20)\n",
        "\n",
        "#### **Grid vs Random Search:**\n",
        "\n",
        "![Grid Random Search](https://pvsmt99345.i.lithium.com/t5/image/serverpage/image-id/74545i97245FDAA10376E9/image-size/large?v=1.0&px=999)\n",
        "\n",
        "\n",
        "### **Otimização Bayesiana:**\n",
        "\n",
        "A otimização Bayesiana de Hiperparâmetros é uma maneira muito eficiente e interessante de se encontrar bons parâmetros. Nesta abordagem, de maneira *naive* é utilizado um modelo de apoio para encontrar os melhores hiperparâmetros. \n",
        "\n",
        "Será utilizado um processo de otimização de hiperparâmetros baseado em um modelo probabilístico, frequentemente gaussiano, para encontrar a partir dos dados observados a distribuição a posteriori da performance dos modelos dado o conjunto de hiperparâmetros testado. \n",
        "\n",
        "![Posteriori](https://miro.medium.com/max/501/1*hk9LX1qkkBmRDyJ-ntLbpw.png)\n",
        "\n",
        "Como é um processo Bayesiano a cada iteração é avaliada a distribuição da performance do modelo em relação aos hiperparâmetros utilizados e gerada uma nova distribuição de probabilidade. Com essa distribuição é possível fazer uma escolha mais adequada do conjunto de valores que vamos utilizar para que nosso algoritmo aprenda da melhor maneira possível.\n",
        "**Resumindo!!!** : É um modelo para otimizar os parâmetros de aprendizagem.\n",
        "\n",
        "Para uma explicação mais técnica do assunto recomendo o seguinte artigo: \n",
        "\n",
        "[Bayes Optim tecnique](https://medium.com/analytics-vidhya/hyperparameter-search-bayesian-optimization-14be6fbb0e09)\n",
        "\n",
        "\n",
        "![Otimização Bayesiana](https://upload.wikimedia.org/wikipedia/commons/0/02/GpParBayesAnimationSmall.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIEdcB2-lzSr",
        "colab_type": "text"
      },
      "source": [
        "## **Outras Considerações sobre Hiperparâmetros:**\n",
        "\n",
        "---\n",
        "\n",
        "### **Tempo de Processamento/Treinamento:**\n",
        "\n",
        "Treinar um modelo, mesmo que seja somente uma vez, pode ser uma tarefa muito custosa. Se precisamos ainda variar hiperparâmetros deste algoritmo devemos encontrar estratégias que são viáveis a infraestrutura e a necessidade de entrega/disponibilidade da área de negócio.\n",
        "**Cuidado!!!** : Existe um GAP GIGANTESCO entre o modelo que o cientista treina no seu Notebook e um modelo implantado. Portanto leve isso em consideração!\n",
        "\n",
        "### **-Durante Desenvolvimento:**\n",
        "\n",
        "Uma estratégia adequada quando enfrentamos grandes volumes de dados é utilizar amostragens na base de treinamento para buscar os melhores hiperparâmetros. Atenção para a necessidade de estratificar e entender qual a representatividade mínima requerida entre as classes de cada feature e também para a variável dependente do modelo.\n",
        "\n",
        "**ALERTA!!!** : JAMAIS faça uma amostragem onde todas as classes das variáveis não estejam representadas nos conjuntos de treino e teste.\n",
        "\n",
        "#### **-Visão Deploy/Implementação**\n",
        "\n",
        "O que diferencia um cientista de um *hobista* dentre muitas coisas é sua capacidade de interpretação de modelos e da sua visão de como um padrão encontrado será implementado na infraestrutura disponível. Portanto para que possamos ser mais profissionais é sempre necessário pensar em como um modelo será implementado desde sua estrutura de estimação até a complexidade/capacidade computacional requerida. O modelo adequado é o que possui boa performance e estabilidade e de fácil implantação/disponibilização.\n",
        "\n",
        "![texto alternativo](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcTyRsDnJyWtY6it8FB65NahezySKeN8hT1fwQ&usqp=CAU)\n",
        "\n",
        "---\n",
        "\n",
        "### **Dificuldade no Aprendizado**\n",
        "\n",
        "*'É meus amigos, até os algoritmos sofrem com esse detalhe *!!!*'*\n",
        "\n",
        "Existem inúmeras situações onde as técnicas de otimização não conseguem convergir para um ponto ótimo, trocando em miúdos, uma otimização pode não ‘otimizar’ (Não Convergir). Técnicas baseadas em descidas de gradiente, BFGS por exemplo, podem ter grandes problemas com pontos críticos locais. Uma alternativa para esse cenário é variar o algoritmo de otimização ou utilizar técnicas de redução de dimensionalidade para simplificar o problema.\n",
        "\n",
        "![texto alternativo](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRz8K1z5brQ0I-2Mk30e_6u8z4y9KQf46Et-w&usqp=CAU)\n",
        "\n",
        "---\n",
        "\n",
        "### **Ausência de Padrões Estimáveis**\n",
        "\n",
        "É possível que dado o conjunto de informações disponíveis não seja possível fazer assunções precisas sobre os dados. Quando o cientista começa a perceber este fato a primeira estratégia é usar parâmetros mais agressivos para entregar um MVP('Mínimo Produto Viável').\n",
        "Ao usar hiperparâmetros muito agressivos, além da perda significativa de explicabilidade pode existir uma redução espúria dos resíduos do modelo. Sendo que essa redução nos erros pode não refletir de forma efetiva o padrão correto dos dados.\n",
        "Um exemplo prático acontece com uma regressão polinomial. Esta técnica é capaz de ajustar perfeitamente qualquer dado linearmente dependente. Esse aumento de complexidade da estrutura apesar de reduzir os erros não reflete a natureza linear do problema. Portanto atenção a isso.\n",
        "\n",
        "**DICA!!!** : Jamais substitua uma estrutura simples e explicável por um modelo complexo de performance equivalente onde você tenha pouco entendimento do que está acontecendo por trás da tela. **Seja Parcimonioso ('Menos é Mais')**\n",
        "\n",
        "---\n",
        "\n",
        "### **Hiperparâmetros Chave:**\n",
        "\n",
        "A grande maioria das técnicas apresenta um conjunto pequeno de Hiperparâmetros que são responsáveis pela maior parte do ajuste do modelo. Em uma árvore de decisão, por exemplo, a profundidade e proporção de indivíduos em cada nó/folha são chaves, portanto, a escolha correta destes hiperparâmetros já pode ser suficiente para um bom ajuste.\n",
        "\n",
        "![Parâmetros da Árvore](https://gblobscdn.gitbook.com/assets%2F-LagOeJ2nL90MQERwhxy%2F-LjmGR4-Zkpsp-CXV3zt%2F-Lk-zlkug29fjZ6T44mL%2Fimage.png?alt=media&token=f775f1ce-2256-4172-af1b-e66e916ec127)\n",
        "\n",
        "**DICA!!!** : Entenda o que é mais importante no algoritmo e foque nele. Não é necessário saber todos os Hiperparâmetros, mas alguns são **Obrigatórios para usar corretamente o Algoritmo**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Estabilidade:**\n",
        "\n",
        "Não escolha hiperparâmetros que gerem resultados instáveis na validação cruzada. Estabilidade é de extrema importância e vai ajudar a manter a robustez do modelo pós implantação.\n",
        "\n",
        "**DICA!!!** : Um K-Fold bem feito ‘resolve’ quase tudo!.\n",
        "\n",
        "![Cross Valid](https://scikit-learn.org/stable/_images/sphx_glr_plot_nested_cross_validation_iris_thumb.png)\n",
        "\n",
        "---\n",
        "\n",
        "### **Replicabilidade e Interpretabilidade:**\n",
        "\n",
        "**Não esqueça a SEMENTE!!**\n",
        "\n",
        "**Saiba INTERPRETAR o seu Modelo !!**\n",
        "\n",
        "**Não esqueça a SEMENTE!!**\n",
        "\n",
        "**Saiba INTERPRETAR o seu Modelo !!**\n",
        "\n",
        "**Não esqueça a SEMENTE!!**\n",
        "\n",
        "Modelos não ***REPLICÁVEIS/INTERPRETÁVEIS*** são **Inúteis** . \n",
        "\n",
        "![](https://pbs.twimg.com/profile_images/826949157109784576/3De8Hvjy.jpg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOdq7Y1_CZtH",
        "colab_type": "text"
      },
      "source": [
        "## **Consideração Final:**\n",
        "\n",
        "Escolha sempre o conjunto de hiperparâmetros que minimize os erros mas que também reduza o GAP de performance entre as bases de treinamento e teste. Não é interessante estimar uma estrutura que se comporte de uma forma quando é observada e de outra quando está fora da amostra.\n",
        "\n",
        "**NeRd!!!** : A não ser que você esteja no mundo quântico. Mas isso é só na casa dos nanômetros pra baixo kkk.\n",
        "\n",
        "\n",
        "![Train/Valid/Test](https://cdn-images-1.medium.com/max/1600/1*vuZxFMi5fODz2OEcpG-S1g.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzvzGKFJ4mrb",
        "colab_type": "text"
      },
      "source": [
        "# Conclusão:\n",
        "\n",
        "Foram abordados conceitos básicos sobre otimização de hiperparâmetros e dicas de como fazer essa tarefa mega importante no processo de modelagem de uma maneira mais efetiva. \n",
        "\n",
        "A teoria está posta, agora vamos para a prática. Separei exemplos de otimização de hiperparâmetros em técnicas diferentes para fixar o conteúdo e vermos como funciona na prática.\n",
        "\n",
        "# Feedback:\n",
        "\n",
        "Obrigado pela Leitura. Caso deseje envie seu feedback pelo : [Contato](https://www.thiagocarmonunes.com.br/sobre/#contact)\n",
        "\n",
        "# Hands On:\n",
        "\n",
        "Acesse via Links:\n",
        "\n",
        "*   [Árvore de Decisão](https://www.thiagocarmonunes.com.br/artigos/HyperParOptim/Tree/)\n",
        "*   [LGBM - Classificação](https://www.thiagocarmonunes.com.br/artigos/HyperParOptim/LGBM/)\n",
        "*   [XGB - Classificação](https://www.thiagocarmonunes.com.br/artigos/HyperParOptim/XGB/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBpNSumOq0LT",
        "colab_type": "text"
      },
      "source": [
        "### Referências:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elE3QW2nq5ga",
        "colab_type": "text"
      },
      "source": [
        "[Portal Action : Estimando os Parâmetros dos Modelos](http://www.portalaction.com.br/confiabilidade/42-estimando-os-parametros-dos-modelos#:~:text=Os%20modelos%20probabil%C3%ADsticos%20apresentados%20na,por%20quantidades%20desconhecidas%2C%20denominadas%20par%C3%A2metros.&text=Essas%20quantidades%20conferem%20uma%20forma%20geral%20aos%20modelos%20probabil%C3%ADsticos.)\n",
        "\n",
        "[Wikipedia : Hyperparameter](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning))\n",
        "\n",
        "\n",
        "[Understanding Hyperparameters and its Optimisation techniques](https://mc.ai/understanding-hyperparameters-and-its-optimisation-techniques/)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "![](https://theamericanreligion.files.wordpress.com/2012/05/porky_pig-5171.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN2HJn-CTkdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}